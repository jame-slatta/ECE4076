{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets play pool\n",
    "\n",
    "Today, we will look at image rectification, a common need for a wide range of applications. Here, we will try to undo perspective effects to get a birds-eye view. This is very useful in sport, augmented reality and robotics applications. A similar technique is used to warp sponsor logos to undo unwanted perspective effects from cameras in support of advertising.  \n",
    "\n",
    "We'll also use today to highlight just how useful the RANSAC technique we taught is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython import display\n",
    "\n",
    "from jupyterquiz import display_quiz\n",
    "import json\n",
    "with open(\"./Questions_week_5.json\", \"r\") as file:\n",
    "    questions = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = cv2.imread('../test_images/pool.png')[:,:,[2,1,0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(im)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's find the boundaries of the table by segmenting out the blue region and then get some edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "felt = (im[:,:,2]<165)&(im[:,:,2]>135)&(im[:,:,0]<35)\n",
    "plt.imshow(felt)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = cv2.Canny(felt.astype(np.uint8)*255,100,200)\n",
    "\n",
    "plt.imshow(edges,cmap = 'gray')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last week we saw that ransac was a really good way of fitting homographies, by discarding outliers, but this idea can be used to fit any model. Let's use it to fit straight lines to find the edges of the pool table.\n",
    "\n",
    "We'll extend ransac to return the 4 best lines with sufficient evidence (an edge response), and with an intersection point on the y-axis that differs from others.\n",
    "\n",
    "Recall that the equation of a line is $ax + by + c = 0$, we can draw two edge points at random, fit a line through these, and then check consensus, repeating until we find all the key lines. We'll use lines and conics to achieve this efficiently. Let's visualise this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all edgels\n",
    "points_x,points_y = np.where(edges>0)\n",
    "# convert to homogenous coordinates\n",
    "points_homog = np.vstack([points_x,points_y,np.ones(len(points_x))]).T\n",
    "\n",
    "for j in range(20):\n",
    "    \n",
    "    # Pick two points at random\n",
    "    bins = np.random.choice(len(points_x),2,replace=False)\n",
    "\n",
    "    # find the line intersecting these using the cross (wedge) product\n",
    "    line = np.cross(points_homog[bins[0],:],points_homog[bins[1],:])\n",
    "\n",
    "    # Check how many other points lie within 5 pixels of this using the dot product\n",
    "    consensus = (np.abs(np.sum(line*points_homog,axis=-1)) < 5)\n",
    "   \n",
    "    plt.clf()\n",
    "    plt.plot(points_homog[bins,1],points_homog[bins,0])\n",
    "    bins_c = consensus\n",
    "   \n",
    "    plt.plot(points_homog[~bins_c,1],points_homog[~bins_c,0],'g.')\n",
    "    plt.plot(points_homog[bins_c,1],points_homog[bins_c,0],'bo')\n",
    "    plt.title('Consensus %d'%np.sum(consensus))\n",
    "    plt.ylim(edges.shape[0],0)\n",
    "            \n",
    "    display.clear_output(wait=True)\n",
    "    display.display(plt.gcf())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool, let's turn this into a function to find the boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ransac_line(image,N=1000,max_error=5, existing_line_threshold=5):\n",
    "    \n",
    "    good_lines = []\n",
    "    consensus_list = []\n",
    "    \n",
    "    points_x,points_y = np.where(edges>0)\n",
    "    points_homog = np.vstack([points_x,points_y,np.ones(len(points_x))]).T\n",
    "    \n",
    "    for j in range(N):\n",
    "\n",
    "        bins = np.random.choice(len(points_x),2,replace=False)\n",
    "\n",
    "        line = np.cross(points_homog[bins[0],:],points_homog[bins[1],:])\n",
    "        \n",
    "        line = line/np.sqrt(line[0]**2 + line[1]**2)\n",
    "        \n",
    "        line = line.reshape(1,3)\n",
    "\n",
    "        consensus = np.sum((np.abs(np.sum(line*points_homog,axis=-1)) <= max_error))\n",
    "        \n",
    "        if len(good_lines) > 0:\n",
    "\n",
    "\n",
    "            # Check if line already found by comparing intercepts\n",
    "            c_good = -np.vstack(good_lines)[:,2]/(np.vstack(good_lines)[:,0]+1e-19)\n",
    "            c_line = -line[0,2]/(line[0,0]+1e-19)  \n",
    "\n",
    "            d = np.abs(c_good-c_line)\n",
    "            best_d = np.argmin(d)\n",
    "\n",
    "            # Check if line alread exists \n",
    "            if (np.min(d) < existing_line_threshold):\n",
    "                #if better than current consensus, replace line\n",
    "                if (np.sum(d<existing_line_threshold)==1)&(consensus > consensus_list[best_d]): # existing line\n",
    "                    good_lines[best_d] = line\n",
    "                    consensus_list[best_d] = consensus\n",
    "                    \n",
    "            else:\n",
    "                # less than 4 lines - add a new one\n",
    "                if len(good_lines) < 4:\n",
    "                    good_lines.append(line)\n",
    "                    consensus_list.append(consensus)    \n",
    "                # more than four lines, replace if better than worst line consensus\n",
    "                elif (consensus > np.min(np.array(consensus_list))):\n",
    "                    worst_consensus = np.argmin(np.array(consensus_list))\n",
    "                    good_lines[worst_consensus] = line\n",
    "                    consensus_list[worst_consensus] = consensus\n",
    "            \n",
    "        else:\n",
    "            good_lines.append(line)\n",
    "            consensus_list.append(consensus)\n",
    "\n",
    "        # Some plotting\n",
    "        if (j %100==0):\n",
    "            plt.clf()\n",
    "            plt.title(consensus_list)\n",
    "            plt.imshow(edges,cmap = 'gray')\n",
    "            x = np.linspace(0,edges.shape[0]-1,edges.shape[0],dtype=int)\n",
    "            for l in good_lines:\n",
    "                l = l.ravel()\n",
    "                #ax + by + c = 0 y = -ax/b -c/b\n",
    "                m = -l[0]/(l[1]+1e-19)\n",
    "                c = -l[2]/(l[1]+1e-19)    \n",
    "                \n",
    "                plt.plot(m*x + c,x)\n",
    "            m = -line[0,0]/(line[0,1]+1e-19)\n",
    "            c = -line[0,2]/(line[0,1]+1e-19)    \n",
    "            plt.plot(m*x + c,x)\n",
    "\n",
    "            plt.xlim(0,edges.shape[1])\n",
    "            plt.ylim(edges.shape[0],0)\n",
    "            display.clear_output(wait=True)\n",
    "            display.display(plt.gcf())\n",
    "\n",
    "        \n",
    "\n",
    "    return good_lines, consensus_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(edges,cmap = 'gray')\n",
    "\n",
    "lines,consensus_list = ransac_line(edges,N=5000,max_error=2,existing_line_threshold=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0,edges.shape[0]-1,edges.shape[0],dtype=int)\n",
    "for l in lines:\n",
    "    l = l.ravel()\n",
    "    #ax + by + c = 0 y = -ax/b -c/b\n",
    "    m = -l[0]/(l[1]+1e-19)\n",
    "    c = -l[2]/(l[1]+1e-19)    \n",
    "    plt.plot(m*x + c,x)\n",
    "\n",
    "plt.xlim(0,edges.shape[1])\n",
    "plt.ylim(edges.shape[0],0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activity 1\n",
    "\n",
    "- Write pseudocode to find all the circles in the image using a ransac-like approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets find the corners, by getting the intercepts using the cross product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intercepts = []\n",
    "plt.imshow(edges)\n",
    "for l1 in lines:\n",
    "    for l2 in lines:\n",
    "        \n",
    "        point = np.cross(l1,l2)\n",
    "        point = point/(point[0,2]+1e-19)\n",
    "        plt.plot(point[0,1],point[0,0],'o')\n",
    "        \n",
    "        if (point[0,0]>0)&(point[0,1]>0)&(point[0,0]<edges.shape[0])&(point[0,1]<edges.shape[1]):\n",
    "            intercepts.append(point)\n",
    "        \n",
    "plt.xlim(0,edges.shape[1])\n",
    "plt.ylim(edges.shape[0],0)\n",
    "plt.show()\n",
    "\n",
    "intercepts = np.unique(np.vstack((intercepts)),axis=0)\n",
    "intercepts = intercepts[np.argsort(intercepts[:,0]),:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To rectify this image, I want to warp it so that the points I've detected move to the 4 corners of the image, as plotted below. We'll do this by solving for the homography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_corners = np.array([[0,edges.shape[1]],\n",
    "                          [edges.shape[0],edges.shape[1]],\n",
    "                          [0,0],\n",
    "                         [edges.shape[0],0]])\n",
    "\n",
    "#Sanity check on correspondences\n",
    "colour_list = ['b','g','r','m']\n",
    "plt.imshow(im)\n",
    "for i in range(4):\n",
    "    plt.plot(intercepts[i,1],intercepts[i,0],'o',color=colour_list[i])\n",
    "    plt.plot(image_corners[i,1],image_corners[i,0],'o',color=colour_list[i])\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H,_ = cv2.findHomography(intercepts[:,[1,0]],image_corners[:,[1,0]],method=0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The homography maps intercepts onto image corners, using the transform\n",
    "\n",
    "$\\begin{bmatrix}u'\\\\v'\\\\1 \\end{bmatrix} = \\mathbf{H} \\begin{bmatrix}u\\\\v\\\\1 \\end{bmatrix}$\n",
    "\n",
    "Applying this to all pixels rectifies our image. We can now do all sorts of future steps, eg. build a best shot predictor by detecting ball colours and assessing complexity using angles to pockets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rectified_image = cv2.warpPerspective(im,H,(edges.shape[1],edges.shape[0]))\n",
    "\n",
    "plt.imshow(rectified_image,cmap='gray')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activity 2\n",
    "\n",
    "- Convince yourself that lines are transformed using the equation $l' = \\mathbf{H}^{-\\text{T}} l$ \n",
    "- The code below applies the homography to lines. Why do lines with near zero elements indicate?\n",
    "- Why is $ax+by+c =0$ a better representation of a line than $y=mx+c$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0,edges.shape[0]-1,edges.shape[0],dtype=int)\n",
    "\n",
    "for i, l in enumerate(lines):\n",
    "    lp = (np.linalg.inv(H).T)@l[:,[1,0,2]].T\n",
    "    \n",
    "    lp = lp/(lp[0]**2+lp[1]**2)\n",
    "    \n",
    "    print('Line %d: \\n '%(i+1), lp.ravel())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_quiz(questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrap up:\n",
    "\n",
    "Some take home messages. \n",
    "\n",
    "- Images and objects in these have geometric properties that impose a range of constraints (eg. Lines, circles).\n",
    "- Camera's are ANGLE and intensity sensors, and subject to perspective geometry effects.\n",
    "- We can use these constraints to aid in various detection strategies\n",
    "- This is quite useful in a range of applications, particularly when you have a lot of prior knowledge about the problem (eg. sport, many industrial production lines).\n",
    "- BUT, these approaches are difficult to tune, and require MANY hand-tuned thresholds\n",
    "- As a result, it's quite easy to make these work on one image, only to find them fail on another\n",
    "- Data-driven approaches (like neural networks) and systematic testing strategies can avoid this.\n",
    "- Incorporating these geometric constraints into data-driven techniques is an active area of research in computer vision"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
